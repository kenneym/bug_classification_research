{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF/IDF and Embedding Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**: This Notebook attempts to concatenate TF/IDF vectors and embedding vectors from TensorHub model & Create a combined model that uses both sources of data. We found that this model did not outperform our standard TF/IDF model, and so we did not pursue it further.\n",
    "\n",
    "**Note**: To run this notebook, you must have previously preproccessed the email data. To preprocess the email data and pickle it for later use, run up until the preproccessing steps in the `tfidf-model` ipynb file (located in `../tfidf_models`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors: Jake Epstein & Matt Kenney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.1\n",
      "Eager mode:  True\n",
      "Hub version:  0.7.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU, Dropout, Flatten, Input\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../nlp_engine')\n",
    "from MLFunctions import PrintDot, plot_history, clear_memory, test_with_uncertainty, predict_with_uncertainty, get_monte_carlo_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data from pickle, put into correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_bugs = pd.read_pickle(\"../data/pickles/preprocessed_bugs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v  dx  api  automation  need  description  fix swagger  generator  use  automation  short  description  description  exist  v  dx  api  proper  short  description  assignment  v  list  assignment  case  view  v  view  metadata  give  case  note  properly  openapi  tab  private  edit  rest  service  rule  questionsave  it  refresh'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_bugs['combined'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'combined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up TF/IDF and Bytes Literal Text (to be fed into Google Hub Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode labels\n",
    "backlog_labels = pd.get_dummies(assigned_bugs['backlog_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_literal_text = assigned_bugs[category].astype('|S') # Bytes Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels for tf/idf and embedding\n",
    "seed = np.random.randint(1000)\n",
    "train_tf_features, test_tf_features, train_labels, test_labels = train_test_split(assigned_bugs[category], backlog_labels, test_size=0.2, random_state=seed)\n",
    "train_em_features, test_em_features, train_labels, test_labels = train_test_split(bytes_literal_text, backlog_labels, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4347, 16675)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Use a TF/IDF Vectorizer to convert plain text descprtions into TF/IDF vectors.\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True,\n",
    "                        binary=False,\n",
    "                        min_df=3,\n",
    "                        max_df=0.5, \n",
    "                        norm='l2', \n",
    "                        ngram_range=(1, 2),\n",
    "                        lowercase=True)\n",
    "\n",
    "train_tf_features = pd.DataFrame(tfidf_vectorizer.fit_transform(train_tf_features).toarray()) # Fit the Vectorizer to the train data\n",
    "test_tf_features = pd.DataFrame(tfidf_vectorizer.transform(train_em_features).toarray()) # Only transform (don't fit) the test data to emulate real-world predictions\n",
    "\n",
    "#hashing_vectorizer = HashingVectorizer(n_features=2**14)\n",
    "#train_features = pd.DataFrame(hashing_vectorizer.transform(train_features).toarray())\n",
    "#test_features = pd.DataFrame(hashing_vectorizer.transform(test_features).toarray())\n",
    "\n",
    "train_tf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_features = train_tf_features.astype('float32')\n",
    "test_tf_features = test_tf_features.astype('float32')\n",
    "train_labels = train_labels.astype('float32')\n",
    "test_labels = test_labels.astype('float32')\n",
    "\n",
    "# Leave train em features as bytes literal since this is what google hub model expects\n",
    "# train_em_features = pd.DataFrame(train_em_features)\n",
    "# test_em_features = pd.DataFrame(test_em_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_entire(embedding_model_url, emfeatures, tffeatures, labels, optimizer, lr, activation, embedding_layer_size, layer1_size, layer2_size=None, layer3_size=None, dropout_rate=0.3, mc=False):\n",
    "    \n",
    "    main_input = Input(shape=[], dtype=tf.string, name='main_input')\n",
    "    hub_layer = hub.KerasLayer(embedding_model_url, input_shape=[], dtype=tf.string, trainable=False)\n",
    "    hub_out = hub_layer(main_input)\n",
    "    \n",
    "    auxiliary_input = Input(shape=(len(tffeatures.keys()),), name='aux_input')\n",
    "    \n",
    "    ## Embedding Output\n",
    "    emb_x = Dense(embedding_layer_size, activation=activation)(hub_out)\n",
    "    embedding_output = Dense(len(labels.keys()), activation='softmax', name='embedding_output')(emb_x)\n",
    "    \n",
    "    \n",
    "    ## Combined Output\n",
    "    x = keras.layers.concatenate([hub_out, auxiliary_input])\n",
    "\n",
    "    x = Dropout(dropout_rate, trainable=mc)(x)\n",
    "    x = Dense(layer1_size, activation=activation)(x)\n",
    "    \n",
    "    if layer2_size:\n",
    "        x = Dropout(dropout_rate, trainable=mc)(x)\n",
    "        x = Dense(layer2_size, activation=activation)(x)\n",
    "    \n",
    "    if layer3_size:\n",
    "        x = Dropout(dropout_rate, trainable=mc)(x)\n",
    "        x = Dense(layer3_size, activation=activation)(x)\n",
    "    \n",
    "    x = Dropout(dropout_rate, trainable=mc)(x)\n",
    "    main_output = Dense(len(labels.keys()), activation='softmax', name='main_output')(x)\n",
    "    \n",
    "    model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, embedding_output])\n",
    "    \n",
    "    \n",
    "    # Parameters\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(lr)\n",
    "        \n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = tf.keras.optifmizers.RMSprop(lr)\n",
    "        \n",
    "    else:\n",
    "        print(\"ERROR: No optimizer passed\")\n",
    "        return None\n",
    "\n",
    "    model.compile(loss='kullback_leibler_divergence',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model already exists, make sure to deallocate it & clear system memory before allocating a new model:\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    model = None\n",
    "    \n",
    "clear_memory(model) # Clear VRAM or RAM\n",
    "\n",
    "model = build_entire(embedding_model_url=\"https://tfhub.dev/google/universal-sentence-encoder/4\", \n",
    "             emfeatures=train_em_features, \n",
    "             tffeatures=train_tf_features, \n",
    "             labels=train_labels, \n",
    "             optimizer='adam', \n",
    "             lr=0.0001,\n",
    "             activation='tanh',\n",
    "             embedding_layer_size=256,\n",
    "             layer1_size =2048,\n",
    "             layer2_size=512, \n",
    "             layer3_size=None,\n",
    "             dropout_rate=0.3, \n",
    "             mc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        (None, 512)          256797824   main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 16675)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 17187)        0           keras_layer[0][0]                \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 17187)        0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         35201024    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1049088     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          131328      keras_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 47)           24111       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_output (Dense)        (None, 47)           12079       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 293,215,454\n",
      "Trainable params: 36,417,630\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3912 samples, validate on 435 samples\n",
      "Epoch 1/1000\n",
      "3912/3912 [==============================] - 7s 2ms/sample - loss: 6.9315 - main_output_loss: 3.2536 - embedding_output_loss: 3.6776 - main_output_accuracy: 0.1904 - embedding_output_accuracy: 0.1595 - val_loss: 6.3837 - val_main_output_loss: 2.8949 - val_embedding_output_loss: 3.4750 - val_main_output_accuracy: 0.2897 - val_embedding_output_accuracy: 0.1931\n",
      "Epoch 2/1000\n",
      "3912/3912 [==============================] - 4s 989us/sample - loss: 5.8762 - main_output_loss: 2.4932 - embedding_output_loss: 3.3790 - main_output_accuracy: 0.3850 - embedding_output_accuracy: 0.1743 - val_loss: 5.6175 - val_main_output_loss: 2.3124 - val_embedding_output_loss: 3.2848 - val_main_output_accuracy: 0.3908 - val_embedding_output_accuracy: 0.1931\n",
      "Epoch 3/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 5.1192 - main_output_loss: 1.8840 - embedding_output_loss: 3.2376 - main_output_accuracy: 0.5573 - embedding_output_accuracy: 0.1743 - val_loss: 5.1205 - val_main_output_loss: 1.8965 - val_embedding_output_loss: 3.2029 - val_main_output_accuracy: 0.5333 - val_embedding_output_accuracy: 0.1931\n",
      "Epoch 4/1000\n",
      "3912/3912 [==============================] - 4s 999us/sample - loss: 4.5718 - main_output_loss: 1.4228 - embedding_output_loss: 3.1433 - main_output_accuracy: 0.6874 - embedding_output_accuracy: 0.1853 - val_loss: 4.7802 - val_main_output_loss: 1.6197 - val_embedding_output_loss: 3.1392 - val_main_output_accuracy: 0.6138 - val_embedding_output_accuracy: 0.2023\n",
      "Epoch 5/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 4.1524 - main_output_loss: 1.0875 - embedding_output_loss: 3.0677 - main_output_accuracy: 0.7730 - embedding_output_accuracy: 0.2060 - val_loss: 4.5007 - val_main_output_loss: 1.4080 - val_embedding_output_loss: 3.0731 - val_main_output_accuracy: 0.6575 - val_embedding_output_accuracy: 0.2207\n",
      "Epoch 6/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 3.8145 - main_output_loss: 0.8227 - embedding_output_loss: 2.9880 - main_output_accuracy: 0.8517 - embedding_output_accuracy: 0.2275 - val_loss: 4.2659 - val_main_output_loss: 1.2433 - val_embedding_output_loss: 3.0052 - val_main_output_accuracy: 0.7218 - val_embedding_output_accuracy: 0.2253\n",
      "Epoch 7/1000\n",
      "3912/3912 [==============================] - 4s 985us/sample - loss: 3.5386 - main_output_loss: 0.6263 - embedding_output_loss: 2.9147 - main_output_accuracy: 0.8937 - embedding_output_accuracy: 0.2439 - val_loss: 4.0926 - val_main_output_loss: 1.1376 - val_embedding_output_loss: 2.9394 - val_main_output_accuracy: 0.7448 - val_embedding_output_accuracy: 0.2483\n",
      "Epoch 8/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 3.3206 - main_output_loss: 0.4836 - embedding_output_loss: 2.8393 - main_output_accuracy: 0.9233 - embedding_output_accuracy: 0.2628 - val_loss: 3.9568 - val_main_output_loss: 1.0710 - val_embedding_output_loss: 2.8731 - val_main_output_accuracy: 0.7563 - val_embedding_output_accuracy: 0.2759\n",
      "Epoch 9/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 3.1483 - main_output_loss: 0.3831 - embedding_output_loss: 2.7646 - main_output_accuracy: 0.9361 - embedding_output_accuracy: 0.2820 - val_loss: 3.8472 - val_main_output_loss: 1.0230 - val_embedding_output_loss: 2.8103 - val_main_output_accuracy: 0.7563 - val_embedding_output_accuracy: 0.2966\n",
      "Epoch 10/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.9909 - main_output_loss: 0.2968 - embedding_output_loss: 2.6902 - main_output_accuracy: 0.9560 - embedding_output_accuracy: 0.2998 - val_loss: 3.7534 - val_main_output_loss: 0.9897 - val_embedding_output_loss: 2.7505 - val_main_output_accuracy: 0.7609 - val_embedding_output_accuracy: 0.3011\n",
      "Epoch 11/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.8632 - main_output_loss: 0.2369 - embedding_output_loss: 2.6227 - main_output_accuracy: 0.9673 - embedding_output_accuracy: 0.3200 - val_loss: 3.6689 - val_main_output_loss: 0.9641 - val_embedding_output_loss: 2.6921 - val_main_output_accuracy: 0.7586 - val_embedding_output_accuracy: 0.3034\n",
      "Epoch 12/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.7549 - main_output_loss: 0.1940 - embedding_output_loss: 2.5663 - main_output_accuracy: 0.9719 - embedding_output_accuracy: 0.3318 - val_loss: 3.6048 - val_main_output_loss: 0.9541 - val_embedding_output_loss: 2.6408 - val_main_output_accuracy: 0.7609 - val_embedding_output_accuracy: 0.3126\n",
      "Epoch 13/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.6640 - main_output_loss: 0.1634 - embedding_output_loss: 2.5062 - main_output_accuracy: 0.9765 - embedding_output_accuracy: 0.3546 - val_loss: 3.5379 - val_main_output_loss: 0.9384 - val_embedding_output_loss: 2.5891 - val_main_output_accuracy: 0.7586 - val_embedding_output_accuracy: 0.3149\n",
      "Epoch 14/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.5747 - main_output_loss: 0.1294 - embedding_output_loss: 2.4452 - main_output_accuracy: 0.9819 - embedding_output_accuracy: 0.3668 - val_loss: 3.4879 - val_main_output_loss: 0.9350 - val_embedding_output_loss: 2.5442 - val_main_output_accuracy: 0.7678 - val_embedding_output_accuracy: 0.3264\n",
      "Epoch 15/1000\n",
      "3912/3912 [==============================] - 4s 994us/sample - loss: 2.5153 - main_output_loss: 0.1240 - embedding_output_loss: 2.3899 - main_output_accuracy: 0.9813 - embedding_output_accuracy: 0.3814 - val_loss: 3.4467 - val_main_output_loss: 0.9360 - val_embedding_output_loss: 2.5010 - val_main_output_accuracy: 0.7632 - val_embedding_output_accuracy: 0.3356\n",
      "Epoch 16/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.4486 - main_output_loss: 0.1060 - embedding_output_loss: 2.3402 - main_output_accuracy: 0.9834 - embedding_output_accuracy: 0.3906 - val_loss: 3.4123 - val_main_output_loss: 0.9399 - val_embedding_output_loss: 2.4605 - val_main_output_accuracy: 0.7586 - val_embedding_output_accuracy: 0.3448\n",
      "Epoch 17/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.3880 - main_output_loss: 0.0927 - embedding_output_loss: 2.2955 - main_output_accuracy: 0.9849 - embedding_output_accuracy: 0.3995 - val_loss: 3.3722 - val_main_output_loss: 0.9393 - val_embedding_output_loss: 2.4227 - val_main_output_accuracy: 0.7678 - val_embedding_output_accuracy: 0.3471\n",
      "Epoch 18/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.3367 - main_output_loss: 0.0869 - embedding_output_loss: 2.2504 - main_output_accuracy: 0.9852 - embedding_output_accuracy: 0.4087 - val_loss: 3.3410 - val_main_output_loss: 0.9450 - val_embedding_output_loss: 2.3878 - val_main_output_accuracy: 0.7632 - val_embedding_output_accuracy: 0.3494\n",
      "Epoch 19/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.2878 - main_output_loss: 0.0786 - embedding_output_loss: 2.2107 - main_output_accuracy: 0.9847 - embedding_output_accuracy: 0.4156 - val_loss: 3.3031 - val_main_output_loss: 0.9394 - val_embedding_output_loss: 2.3556 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.3609\n",
      "Epoch 20/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.2418 - main_output_loss: 0.0728 - embedding_output_loss: 2.1691 - main_output_accuracy: 0.9854 - embedding_output_accuracy: 0.4259 - val_loss: 3.2727 - val_main_output_loss: 0.9397 - val_embedding_output_loss: 2.3242 - val_main_output_accuracy: 0.7609 - val_embedding_output_accuracy: 0.3678\n",
      "Epoch 21/1000\n",
      "3912/3912 [==============================] - 4s 989us/sample - loss: 2.1995 - main_output_loss: 0.0680 - embedding_output_loss: 2.1325 - main_output_accuracy: 0.9854 - embedding_output_accuracy: 0.4348 - val_loss: 3.2443 - val_main_output_loss: 0.9394 - val_embedding_output_loss: 2.2963 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.3701\n",
      "Epoch 22/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.1664 - main_output_loss: 0.0760 - embedding_output_loss: 2.0971 - main_output_accuracy: 0.9836 - embedding_output_accuracy: 0.4407 - val_loss: 3.2211 - val_main_output_loss: 0.9463 - val_embedding_output_loss: 2.2678 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.3770\n",
      "Epoch 23/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.1284 - main_output_loss: 0.0663 - embedding_output_loss: 2.0611 - main_output_accuracy: 0.9839 - embedding_output_accuracy: 0.4484 - val_loss: 3.2108 - val_main_output_loss: 0.9578 - val_embedding_output_loss: 2.2422 - val_main_output_accuracy: 0.7678 - val_embedding_output_accuracy: 0.3862\n",
      "Epoch 24/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.0870 - main_output_loss: 0.0575 - embedding_output_loss: 2.0309 - main_output_accuracy: 0.9862 - embedding_output_accuracy: 0.4573 - val_loss: 3.1789 - val_main_output_loss: 0.9572 - val_embedding_output_loss: 2.2161 - val_main_output_accuracy: 0.7770 - val_embedding_output_accuracy: 0.4023\n",
      "Epoch 25/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.0586 - main_output_loss: 0.0601 - embedding_output_loss: 1.9991 - main_output_accuracy: 0.9829 - embedding_output_accuracy: 0.4701 - val_loss: 3.1594 - val_main_output_loss: 0.9595 - val_embedding_output_loss: 2.1918 - val_main_output_accuracy: 0.7701 - val_embedding_output_accuracy: 0.4092\n",
      "Epoch 26/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 2.0240 - main_output_loss: 0.0548 - embedding_output_loss: 1.9645 - main_output_accuracy: 0.9857 - embedding_output_accuracy: 0.4757 - val_loss: 3.1360 - val_main_output_loss: 0.9601 - val_embedding_output_loss: 2.1702 - val_main_output_accuracy: 0.7632 - val_embedding_output_accuracy: 0.4115\n",
      "Epoch 27/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.9954 - main_output_loss: 0.0542 - embedding_output_loss: 1.9410 - main_output_accuracy: 0.9865 - embedding_output_accuracy: 0.4816 - val_loss: 3.1214 - val_main_output_loss: 0.9644 - val_embedding_output_loss: 2.1487 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.4138\n",
      "Epoch 28/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.9601 - main_output_loss: 0.0472 - embedding_output_loss: 1.9163 - main_output_accuracy: 0.9888 - embedding_output_accuracy: 0.4847 - val_loss: 3.0966 - val_main_output_loss: 0.9621 - val_embedding_output_loss: 2.1269 - val_main_output_accuracy: 0.7678 - val_embedding_output_accuracy: 0.4184\n",
      "Epoch 29/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.9440 - main_output_loss: 0.0558 - embedding_output_loss: 1.8928 - main_output_accuracy: 0.9854 - embedding_output_accuracy: 0.4941 - val_loss: 3.1020 - val_main_output_loss: 0.9903 - val_embedding_output_loss: 2.1083 - val_main_output_accuracy: 0.7678 - val_embedding_output_accuracy: 0.4253\n",
      "Epoch 30/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.9091 - main_output_loss: 0.0456 - embedding_output_loss: 1.8599 - main_output_accuracy: 0.9882 - embedding_output_accuracy: 0.4997 - val_loss: 3.0697 - val_main_output_loss: 0.9731 - val_embedding_output_loss: 2.0912 - val_main_output_accuracy: 0.7724 - val_embedding_output_accuracy: 0.4276\n",
      "Epoch 31/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.8831 - main_output_loss: 0.0434 - embedding_output_loss: 1.8437 - main_output_accuracy: 0.9882 - embedding_output_accuracy: 0.5049 - val_loss: 3.0647 - val_main_output_loss: 0.9840 - val_embedding_output_loss: 2.0723 - val_main_output_accuracy: 0.7724 - val_embedding_output_accuracy: 0.4276\n",
      "Epoch 32/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.8629 - main_output_loss: 0.0463 - embedding_output_loss: 1.8136 - main_output_accuracy: 0.9870 - embedding_output_accuracy: 0.5087 - val_loss: 3.0476 - val_main_output_loss: 0.9857 - val_embedding_output_loss: 2.0563 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.4322\n",
      "Epoch 33/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.8433 - main_output_loss: 0.0534 - embedding_output_loss: 1.7946 - main_output_accuracy: 0.9872 - embedding_output_accuracy: 0.5176 - val_loss: 3.0312 - val_main_output_loss: 0.9853 - val_embedding_output_loss: 2.0397 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.4345\n",
      "Epoch 34/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.8223 - main_output_loss: 0.0497 - embedding_output_loss: 1.7746 - main_output_accuracy: 0.9844 - embedding_output_accuracy: 0.5204 - val_loss: 3.0165 - val_main_output_loss: 0.9836 - val_embedding_output_loss: 2.0250 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.4414\n",
      "Epoch 35/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.7951 - main_output_loss: 0.0432 - embedding_output_loss: 1.7546 - main_output_accuracy: 0.9882 - embedding_output_accuracy: 0.5261 - val_loss: 3.0289 - val_main_output_loss: 1.0117 - val_embedding_output_loss: 2.0092 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.4414\n",
      "Epoch 36/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.7744 - main_output_loss: 0.0425 - embedding_output_loss: 1.7293 - main_output_accuracy: 0.9882 - embedding_output_accuracy: 0.5289 - val_loss: 3.0131 - val_main_output_loss: 1.0109 - val_embedding_output_loss: 1.9961 - val_main_output_accuracy: 0.7724 - val_embedding_output_accuracy: 0.4437\n",
      "Epoch 37/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.7574 - main_output_loss: 0.0449 - embedding_output_loss: 1.7092 - main_output_accuracy: 0.9872 - embedding_output_accuracy: 0.5332 - val_loss: 2.9997 - val_main_output_loss: 1.0126 - val_embedding_output_loss: 1.9822 - val_main_output_accuracy: 0.7724 - val_embedding_output_accuracy: 0.4483\n",
      "Epoch 38/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.7339 - main_output_loss: 0.0400 - embedding_output_loss: 1.6915 - main_output_accuracy: 0.9870 - embedding_output_accuracy: 0.5424 - val_loss: 3.0139 - val_main_output_loss: 1.0358 - val_embedding_output_loss: 1.9692 - val_main_output_accuracy: 0.7701 - val_embedding_output_accuracy: 0.4598\n",
      "Epoch 39/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.7094 - main_output_loss: 0.0340 - embedding_output_loss: 1.6750 - main_output_accuracy: 0.9893 - embedding_output_accuracy: 0.5452 - val_loss: 2.9867 - val_main_output_loss: 1.0260 - val_embedding_output_loss: 1.9553 - val_main_output_accuracy: 0.7678 - val_embedding_output_accuracy: 0.4621\n",
      "Epoch 40/1000\n",
      "3912/3912 [==============================] - 4s 977us/sample - loss: 1.6960 - main_output_loss: 0.0394 - embedding_output_loss: 1.6557 - main_output_accuracy: 0.9882 - embedding_output_accuracy: 0.5537 - val_loss: 2.9852 - val_main_output_loss: 1.0376 - val_embedding_output_loss: 1.9429 - val_main_output_accuracy: 0.7563 - val_embedding_output_accuracy: 0.4690\n",
      "Epoch 41/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.6845 - main_output_loss: 0.0440 - embedding_output_loss: 1.6370 - main_output_accuracy: 0.9862 - embedding_output_accuracy: 0.5583 - val_loss: 2.9667 - val_main_output_loss: 1.0267 - val_embedding_output_loss: 1.9328 - val_main_output_accuracy: 0.7747 - val_embedding_output_accuracy: 0.4736\n",
      "Epoch 42/1000\n",
      "3912/3912 [==============================] - 4s 996us/sample - loss: 1.6665 - main_output_loss: 0.0431 - embedding_output_loss: 1.6243 - main_output_accuracy: 0.9872 - embedding_output_accuracy: 0.5626 - val_loss: 2.9615 - val_main_output_loss: 1.0353 - val_embedding_output_loss: 1.9218 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.4713\n",
      "Epoch 43/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.6486 - main_output_loss: 0.0411 - embedding_output_loss: 1.6084 - main_output_accuracy: 0.9882 - embedding_output_accuracy: 0.5670 - val_loss: 2.9557 - val_main_output_loss: 1.0382 - val_embedding_output_loss: 1.9096 - val_main_output_accuracy: 0.7655 - val_embedding_output_accuracy: 0.4759\n",
      "Epoch 44/1000\n",
      "3912/3912 [==============================] - 4s 1ms/sample - loss: 1.6347 - main_output_loss: 0.0430 - embedding_output_loss: 1.5910 - main_output_accuracy: 0.9867 - embedding_output_accuracy: 0.5711 - val_loss: 2.9411 - val_main_output_loss: 1.0327 - val_embedding_output_loss: 1.9004 - val_main_output_accuracy: 0.7701 - val_embedding_output_accuracy: 0.4805\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_main_output_accuracy', patience=20)\n",
    "history = model.fit([train_em_features.to_numpy(), train_tf_features.to_numpy()],\n",
    "                    [train_labels.to_numpy(), train_labels.to_numpy()],\n",
    "                    epochs=1000,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks = [early_stop],\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-workspace)",
   "language": "python",
   "name": "nlp-workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
