{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug Classifcation using Natural Language Processing\n",
    "The following project uses a Natural Language Processing model to read in bug descriptions submitted by the Global Customer Support Desk, internal Pega employees, and pega customers, and assign these bugs to the relevant backlogs in Agile Studio.\n",
    "\n",
    "To perform bug assignment, we first pre-process bug descriptions and subject lines. Then, we convert each bug description to a TF/ IDF vector. Finally, we use a Deep Learning model to extract insights from the TF/IDF scores and train that model to perform accurate classifications.\n",
    "\n",
    "At the prediction phase, we apply confidence bounding using [Monte Carlo dropout](https://arxiv.org/pdf/1506.02142.pdf). Using this approach, we can choose the threshold confidence score that best suits our needs - the model will automatically route bugs to the appropriate backlogs if it can generate a prediction above the confidence threshold (a high confidence prediction) and will route bugs that it cannot confidently place into a queue for human review. Stakeholders at Pega can choose a proper trade off between accuracy and efficiency by tweaking the confidence threshold to the desired value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Packages.\n",
    "The first script, [`install_conda.sh`](../nlp_engine/install_conda.sh), installs [miniconda](https://docs.conda.io/en/latest/miniconda.html) and sets up an environment called `nlp-workspace`. You can learn more about conda environments [here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html). The environment essentially acts as a sand-boxed virtual machine where we keep all of the code dependencies. As you can see by inspecting the install script, we use python 3.7 as our base. Further, we install the `nb_conda` package. This package allows us to select an environment on a Jupyter Notebook (nb). Once the `install_conda` script has been run, you should be able to open a jupyter notebook on your host machine and select `Python (nlp-workspace)` as the kernel.\n",
    "\n",
    "\n",
    "The second script, [`install_packages.sh`](../nlp_engine/install_packages.sh), installs all of the requisite python packages necessary to train the machine learning model and deploy it. After successfully running this script, the environment should have all of the necessary packages and all imports should work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this entire selection to perform the requisite installs\n",
    "#%%capture # The capture tag suppresses output. Comment it out if you want to see installation script output.\n",
    "#!bash ../nlp_engine/install_conda.sh\n",
    "#!bash ../nlp_engine/install_packages.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.1\n",
      "Eager mode:  True\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Import all needed libraries from the `nlp-workspace` environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU, Dropout, Flatten, Input, Activation, PReLU, LeakyReLU, ThresholdedReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Pull in additional libraries.\n",
    "Here, we pull in additional libraries that we created to perform standard NLP test preprocessing and convenience functions for machine learning.\n",
    "You can inspect the functions we pull in here by taking a look at our [`MLFunctions`](../nlp_engine/MLFunctions.py) file or our [`Preprocessing`](../nlp_engine/Preprocessing.py) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy model is using GPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../nlp_engine')\n",
    "from MLFunctions import PrintDot, plot_history, clear_memory, test_with_uncertainty, \\\n",
    "                        predict_with_uncertainty, get_monte_carlo_accuracy, graph_confidence\n",
    "from Preprocessing import preprocess_training_text, preprocess_training_text_with_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Read-in and Clean Data\n",
    "Here, we read in the email bug data and eliminate training examples that will not be useful to out model. Starting with the original dataset, we\n",
    "1. **Eliminate** \n",
    "    - bugs that were not assigned to a backlog \n",
    "    - bugs that were not assigned to a team (i.e. bugs that were never resolved)\n",
    "    - bugs that lack a description or label\n",
    "    \n",
    "    \n",
    "2. **Remove duplicate entries, if they exist.**\n",
    "\n",
    "3. **Remove backlogs that have been assigned less than 40 training examples.** Backlogs that have been assigned less than this number will be prone to model over-fitting, since they are so underrepresented in a dataset of the size we are working with. As such, we remove them to avoid inaccurate classifications. We settled on the number 40 after experimenting with a variety of different thresholds, but you may want to change this threshold as you collect additional training data to be fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "      <th>status</th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_name</th>\n",
       "      <th>backlog_id</th>\n",
       "      <th>backlog_name</th>\n",
       "      <th>feature_id</th>\n",
       "      <th>feature_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUG-530021</td>\n",
       "      <td>Issues with Reports and Notifications</td>\n",
       "      <td>Hi Team,\\n\\n\\n\\nThis is to report 2 issues.\\n\\...</td>\n",
       "      <td>Resolved-Enhancement</td>\n",
       "      <td>PROJ-10002</td>\n",
       "      <td>Cloud - Beyonders</td>\n",
       "      <td>BL-3339</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUG-528121</td>\n",
       "      <td>OPD-PROD: Pre schedule validation stuck in pro...</td>\n",
       "      <td>Pre-scheduled validation is stuck at in-progre...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-10002</td>\n",
       "      <td>Cloud - Beyonders</td>\n",
       "      <td>BL-3339</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>FR-9155</td>\n",
       "      <td>Scheduling Patch Installs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUG-529279</td>\n",
       "      <td>For inflight DBupgrde tasks, Validation tasks ...</td>\n",
       "      <td>For inflight DBupgrde tasks, Validation tasks ...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-10002</td>\n",
       "      <td>Cloud - Beyonders</td>\n",
       "      <td>BL-3339</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>FR-8238</td>\n",
       "      <td>Global Operations Console (GOC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUG-528748</td>\n",
       "      <td>Issues in Q_7.22</td>\n",
       "      <td>1. Create a VCR dispute\\n\\r\\n2. Select Quality...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-10005</td>\n",
       "      <td>20.1 Compliance for SD Issuers and Acquirers</td>\n",
       "      <td>GRP-15763</td>\n",
       "      <td>FS - Smart Dispute - Issuer Compliance Backlog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUG-537524</td>\n",
       "      <td>Incorrect Deadline value in overview tab</td>\n",
       "      <td>Steps to reproduce:\\n\\n1. Login to QA server w...</td>\n",
       "      <td>New</td>\n",
       "      <td>PROJ-10005</td>\n",
       "      <td>20.1 Compliance for SD Issuers and Acquirers</td>\n",
       "      <td>GRP-15763</td>\n",
       "      <td>FS - Smart Dispute - Issuer Compliance Backlog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      work_id                                              label  \\\n",
       "0  BUG-530021              Issues with Reports and Notifications   \n",
       "1  BUG-528121  OPD-PROD: Pre schedule validation stuck in pro...   \n",
       "2  BUG-529279  For inflight DBupgrde tasks, Validation tasks ...   \n",
       "3  BUG-528748                                   Issues in Q_7.22   \n",
       "4  BUG-537524           Incorrect Deadline value in overview tab   \n",
       "\n",
       "                                         description                status  \\\n",
       "0  Hi Team,\\n\\n\\n\\nThis is to report 2 issues.\\n\\...  Resolved-Enhancement   \n",
       "1  Pre-scheduled validation is stuck at in-progre...    Resolved-Completed   \n",
       "2  For inflight DBupgrde tasks, Validation tasks ...    Resolved-Completed   \n",
       "3  1. Create a VCR dispute\\n\\r\\n2. Select Quality...    Resolved-Completed   \n",
       "4  Steps to reproduce:\\n\\n1. Login to QA server w...                   New   \n",
       "\n",
       "      team_id                                     team_name backlog_id  \\\n",
       "0  PROJ-10002                             Cloud - Beyonders    BL-3339   \n",
       "1  PROJ-10002                             Cloud - Beyonders    BL-3339   \n",
       "2  PROJ-10002                             Cloud - Beyonders    BL-3339   \n",
       "3  PROJ-10005  20.1 Compliance for SD Issuers and Acquirers  GRP-15763   \n",
       "4  PROJ-10005  20.1 Compliance for SD Issuers and Acquirers  GRP-15763   \n",
       "\n",
       "                                     backlog_name feature_id  \\\n",
       "0                                           Cloud        NaN   \n",
       "1                                           Cloud    FR-9155   \n",
       "2                                           Cloud    FR-8238   \n",
       "3  FS - Smart Dispute - Issuer Compliance Backlog        NaN   \n",
       "4  FS - Smart Dispute - Issuer Compliance Backlog        NaN   \n",
       "\n",
       "                      feature_name  \n",
       "0                              NaN  \n",
       "1        Scheduling Patch Installs  \n",
       "2  Global Operations Console (GOC)  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data & rename columns\n",
    "email_bugs = pd.read_csv(\"../data/csvs/bug_emails.csv\")\n",
    "email_bugs = email_bugs.rename(columns={\"Work ID\" : \"work_id\", \"Label\" : \"label\", \"Description\" : \"description\", \n",
    "                             \"Status\" : \"status\", \"Team ID\" : \"team_id\", \"Team Name\" : \"team_name\", \n",
    "                             \"Backlog ID\" : \"backlog_id\", \"Backlog Name\" : \"backlog_name\", \"Feature ID\" : \"feature_id\", \n",
    "                             \"Feature Name\" : \"feature_name\"})\n",
    "\n",
    "# 1. Eliminate:\n",
    "assigned_bugs = email_bugs[email_bugs['backlog_id'].notnull()]   # bugs that were not assigned to a backlog\n",
    "assigned_bugs = assigned_bugs[assigned_bugs['team_id'].notnull()]  # bugs that lack a team\n",
    "assigned_bugs = assigned_bugs[assigned_bugs['description'].notnull()]  # bugs that lack a description\n",
    "assigned_bugs = assigned_bugs[assigned_bugs['label'].notnull()]        # or label\n",
    "\n",
    "# 2. Drop Duplicates:\n",
    "assigned_bugs.drop_duplicates(subset = \"work_id\", keep = False, inplace = True) # duplicate bugs\n",
    "\n",
    "# Visualize the dataset\n",
    "assigned_bugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of backlog IDs:  159\n",
      "Number of training samples:  7438\n"
     ]
    }
   ],
   "source": [
    "# Check current number of backlogs and samples\n",
    "print(\"Number of backlog IDs: \" , assigned_bugs['backlog_id'].nunique())\n",
    "print(\"Number of training samples: \" , len(assigned_bugs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backlog ID's remaining: 47\n",
      "Number of training samples remaining:  6245\n",
      "% of remaining training examples:  0.8396074213498252\n"
     ]
    }
   ],
   "source": [
    "# 3. Remove backlogs that have been assigned 40 or less training examples:\n",
    "former_length = len(assigned_bugs)\n",
    "bugs_per_id = assigned_bugs['backlog_id'].value_counts()\n",
    "valid_id_list = bugs_per_id[bugs_per_id > 40].index.tolist()\n",
    "assigned_bugs = assigned_bugs[assigned_bugs['backlog_id'].isin(valid_id_list)]\n",
    "\n",
    "print(\"Backlog ID's remaining:\", len(valid_id_list))\n",
    "print(\"Number of training samples remaining: \" , len(assigned_bugs))\n",
    "print(\"% of remaining training examples: \", len(assigned_bugs) / former_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Preprocessing\n",
    "Below, we apply the preprocessing functions we created in our [`Preprocessing`](../nlp_engine/Preprocessing.py) library to our bug descriptions and subject lines ('label'). \n",
    "**The standard preprocessing function applies the following procedures to our bug descriptions:**\n",
    "- Strip HTML\n",
    "- Remove non-ascii characters (i.e. Unicode)\n",
    "- Remove excess whitespace (tabs, newlines, etc.)\n",
    "- Convert accented chars (café -> *cafe*)\n",
    "- Lowercase all characters\n",
    "- Remove numbers (*see note below*)\n",
    "- Remove punctuation\n",
    "- Expand contractions\n",
    "          don't → do not \n",
    "          I'll → I will be\n",
    "- Lemmatization \n",
    "          [Playing, plays, played]→ play\n",
    "          [am, are, is] → be\n",
    "- Remove stop words (the most common words in the English language)\n",
    "          buy a banana at market → buy banana market\n",
    "\n",
    "\n",
    "**Notes**:\n",
    "- You can choose to convert numbers into text (i.e. 7 -> seven) instead of removing them by setting the `convert_num` setting to `True` and the `remove_num` setting to `False`.\n",
    "- Any other of the preprocessing options can be changed simply by toying with the parameters, as you can see we have done with the `preprocess_with_caps` function below.\n",
    "\n",
    "---\n",
    "### Rationale:\n",
    "\n",
    "Each of the above procedures are designed to clean the text and increase its value in terms of the predictive power it delivers. \n",
    "\n",
    "**Lemmatization and contraction expansion** are designed to ensure that phrases and words that mean the same thing are always represented the same way in the text. This way, a machine learning model doesn't need to learn the relationship between play, played, plays, etc. and the prediction it is trying to make. Instead, it only needs to learn the relationship between the single word - play- and the prediction it is trying to make. Lemmatization and contraction expansion therefore work to better capture the semantic meaning of a text and remove variants that might confuse an ML model. \n",
    "\n",
    "**Removing stop words** helps to improve the value of a text by removing all words that lack predictive power, thus allowing an ML model to better \"attend to\" the words that matter.\n",
    "\n",
    "---\n",
    "### Usage:\n",
    "To use our preprocessing function we use the pandas [.apply syntax](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html). When we call `dataframe.apply(function_name)`, we apply that function to all of the entries (bugs) in our DataFrame. When you run the below cells, note that the preprocessing function itself uses a pre-trained machine learning model ([from spacy](https://spacy.io/models)) to perform lemmatization and contraction expansion. As such, the process is computationally intensive. It takes a few minutes to run on a GPU machine, and likely longer on a standard CPU machine.\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Steps:\n",
    "After we finish preprocessing, we **remove all bugs that contain 10 or leas words in the description field**, as these bugs are unlikely to contain enough inferencable information. We perform this step after preprocessing so that we do not include stop words, emails, URLs, numbers, or other non-word symbols in the word count.\n",
    "\n",
    "Its possible that bugs with this few words could have a descriptive subject line, but we found subject lines to be significantly less predictive than the description field, often including only generic descriptions or identification numbers that mean nothing to our model.\n",
    "\n",
    "In our dataset, there are only a few hundred bugs with descriptions of 10 or less words... because we remove them, however, it's worth noting that our model is likely to perform poorly if fed extremely short emails in production unless those emails contain keywords our model has been trained to utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_stops_caps(text):\n",
    "    return preprocess_training_text(text, accented_chars=True, contractions=True, \n",
    "                       convert_num=False, extra_whitespace=True, \n",
    "                       lemmatization=True, lowercase=False, punctuations=False,\n",
    "                       remove_html=True, remove_num=True, special_chars=True, \n",
    "                       stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/nlp-workspace/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "preproccessing descriptions: 100%|██████████| 6245/6245 [02:15<00:00, 46.12it/s]\n",
      "preproccessing labels: 100%|██████████| 6245/6245 [01:48<00:00, 57.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to perform text preprocessing\n",
    "tqdm.pandas(desc=\"preproccessing descriptions\")\n",
    "assigned_bugs['description'] = assigned_bugs['description'].progress_apply(preprocess_training_text)\n",
    "tqdm.pandas(desc=\"preproccessing labels\")\n",
    "assigned_bugs['label'] = assigned_bugs['label'].progress_apply(preprocess_training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate bug labels and descriptions, and create a `combined` data column in our `assigned_bugs` dataframe. \n",
    "# We will pass this data into our ML model, since the label + description combined contains more information than \n",
    "# either text field individually.\n",
    "assigned_bugs['combined'] = assigned_bugs['label'].map(str) + ' ' + assigned_bugs['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples remaining:  5434\n"
     ]
    }
   ],
   "source": [
    "# Additional Step: Remove all bugs that contain 10 or less words in the description:\n",
    "assigned_bugs = assigned_bugs[assigned_bugs['description'].str.split().apply(len) > 10]\n",
    "print(\"Number of training samples remaining: \" , len(assigned_bugs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code snippet can be used to save pre-processed text to a pickle file.\n",
    "By saving the pre-processed text to a pickle, you avoid having to continuously\n",
    "re-run the preprocessing function each time you work with this code. \n",
    "\n",
    "**Once you have run preprocessing on your bug data once, you can skip running the above preprocessing cell and simply load the relevant pickle file to obtain processed text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed bugs\n",
    "pd.to_pickle(assigned_bugs, \"../data/pickles/preprocessed_bugs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the preprocessed bugs (run this to reload\n",
    "# preprocessed data)\n",
    "assigned_bugs = pd.read_pickle(\"../data/pickles/preprocessed_bugs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Bug Text\n",
    "Confirm that the text has been cleaned and processed correctly by examining the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "      <th>Status</th>\n",
       "      <th>team_id</th>\n",
       "      <th>Team Name</th>\n",
       "      <th>backlog_id</th>\n",
       "      <th>Backlog Name</th>\n",
       "      <th>Feature ID</th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUG-530021</td>\n",
       "      <td>issue  report  notification</td>\n",
       "      <td>hi  team  report  issue  pre  schedule  valida...</td>\n",
       "      <td>Resolved-Enhancement</td>\n",
       "      <td>PROJ-10002</td>\n",
       "      <td>Cloud - Beyonders</td>\n",
       "      <td>BL-3339</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>issue  report  notification hi  team  report  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUG-528121</td>\n",
       "      <td>opd  prod  pre  schedule  validation  stick  p...</td>\n",
       "      <td>pre  schedule  validation  stick  progress  go...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-10002</td>\n",
       "      <td>Cloud - Beyonders</td>\n",
       "      <td>BL-3339</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>FR-9155</td>\n",
       "      <td>Scheduling Patch Installs</td>\n",
       "      <td>opd  prod  pre  schedule  validation  stick  p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUG-529279</td>\n",
       "      <td>inflight  dbupgrde  task  validation  task  progr</td>\n",
       "      <td>inflight  dbupgrde  task  validation  task  in...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-10002</td>\n",
       "      <td>Cloud - Beyonders</td>\n",
       "      <td>BL-3339</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>FR-8238</td>\n",
       "      <td>Global Operations Console (GOC)</td>\n",
       "      <td>inflight  dbupgrde  task  validation  task  pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BUG-530336</td>\n",
       "      <td>new  app  wizard  error</td>\n",
       "      <td>laura  protano  run  error  run  new  applicat...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-10010</td>\n",
       "      <td>Zenith for Customer Service 8.5</td>\n",
       "      <td>BL-752</td>\n",
       "      <td>Pega Customer Service Development Backlog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new  app  wizard  error laura  protano  run  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BUG-530860</td>\n",
       "      <td>v  dx  api  automation  need  description  fix</td>\n",
       "      <td>swagger  generator  use  automation  short  de...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-10015</td>\n",
       "      <td>DX APIs - CodeNinjas</td>\n",
       "      <td>GRP-13931</td>\n",
       "      <td>Platform UI Backlog</td>\n",
       "      <td>FR-8192</td>\n",
       "      <td>Web APIs</td>\n",
       "      <td>v  dx  api  automation  need  description  fix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>BUG-534804</td>\n",
       "      <td>qa  incorrect  sale  support  manager  onboard...</td>\n",
       "      <td>url  prweb  step  reproduce  login  john  john...</td>\n",
       "      <td>Resolved-CannotRecreate</td>\n",
       "      <td>PROJ-9995</td>\n",
       "      <td>Symphony [PCLM] 8.4</td>\n",
       "      <td>BL-9394</td>\n",
       "      <td>FS - Client Lifecycle Management (8.4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qa  incorrect  sale  support  manager  onboard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>BUG-535030</td>\n",
       "      <td>fm  manage  product  fund  complete  default</td>\n",
       "      <td>step  start  onboarde  fm  b  add  fund  produ...</td>\n",
       "      <td>Resolved-Enhancement</td>\n",
       "      <td>PROJ-9995</td>\n",
       "      <td>Symphony [PCLM] 8.4</td>\n",
       "      <td>BL-9394</td>\n",
       "      <td>FS - Client Lifecycle Management (8.4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fm  manage  product  fund  complete  default s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7563</th>\n",
       "      <td>BUG-532532</td>\n",
       "      <td>pdc  exception  null  pointer  excep  retail</td>\n",
       "      <td>initial  analysis  initial  analysis  step  ch...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-9995</td>\n",
       "      <td>Symphony [PCLM] 8.4</td>\n",
       "      <td>BL-9394</td>\n",
       "      <td>FS - Client Lifecycle Management (8.4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pdc  exception  null  pointer  excep  retail i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7564</th>\n",
       "      <td>BUG-531668</td>\n",
       "      <td>cib  case  stuck  client  synch  relate  add  ...</td>\n",
       "      <td>create  flat  hierarchical  add  product  cib ...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-9996</td>\n",
       "      <td>Synergy 8.4</td>\n",
       "      <td>BL-9394</td>\n",
       "      <td>FS - Client Lifecycle Management (8.4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cib  case  stuck  client  synch  relate  add  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>BUG-532794</td>\n",
       "      <td>pdc  exception  null  pointer  excepception  g...</td>\n",
       "      <td>initial  analysis  potentially  kyc  issue  ba...</td>\n",
       "      <td>Resolved-Completed</td>\n",
       "      <td>PROJ-9996</td>\n",
       "      <td>Synergy 8.4</td>\n",
       "      <td>BL-9394</td>\n",
       "      <td>FS - Client Lifecycle Management (8.4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pdc  exception  null  pointer  excepception  g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5434 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         work_id                                              label  \\\n",
       "0     BUG-530021                        issue  report  notification   \n",
       "1     BUG-528121  opd  prod  pre  schedule  validation  stick  p...   \n",
       "2     BUG-529279  inflight  dbupgrde  task  validation  task  progr   \n",
       "39    BUG-530336                            new  app  wizard  error   \n",
       "48    BUG-530860     v  dx  api  automation  need  description  fix   \n",
       "...          ...                                                ...   \n",
       "7561  BUG-534804  qa  incorrect  sale  support  manager  onboard...   \n",
       "7562  BUG-535030       fm  manage  product  fund  complete  default   \n",
       "7563  BUG-532532       pdc  exception  null  pointer  excep  retail   \n",
       "7564  BUG-531668  cib  case  stuck  client  synch  relate  add  ...   \n",
       "7567  BUG-532794  pdc  exception  null  pointer  excepception  g...   \n",
       "\n",
       "                                            description  \\\n",
       "0     hi  team  report  issue  pre  schedule  valida...   \n",
       "1     pre  schedule  validation  stick  progress  go...   \n",
       "2     inflight  dbupgrde  task  validation  task  in...   \n",
       "39    laura  protano  run  error  run  new  applicat...   \n",
       "48    swagger  generator  use  automation  short  de...   \n",
       "...                                                 ...   \n",
       "7561  url  prweb  step  reproduce  login  john  john...   \n",
       "7562  step  start  onboarde  fm  b  add  fund  produ...   \n",
       "7563  initial  analysis  initial  analysis  step  ch...   \n",
       "7564  create  flat  hierarchical  add  product  cib ...   \n",
       "7567  initial  analysis  potentially  kyc  issue  ba...   \n",
       "\n",
       "                       Status     team_id                        Team Name  \\\n",
       "0        Resolved-Enhancement  PROJ-10002                Cloud - Beyonders   \n",
       "1          Resolved-Completed  PROJ-10002                Cloud - Beyonders   \n",
       "2          Resolved-Completed  PROJ-10002                Cloud - Beyonders   \n",
       "39         Resolved-Completed  PROJ-10010  Zenith for Customer Service 8.5   \n",
       "48         Resolved-Completed  PROJ-10015             DX APIs - CodeNinjas   \n",
       "...                       ...         ...                              ...   \n",
       "7561  Resolved-CannotRecreate   PROJ-9995              Symphony [PCLM] 8.4   \n",
       "7562     Resolved-Enhancement   PROJ-9995              Symphony [PCLM] 8.4   \n",
       "7563       Resolved-Completed   PROJ-9995              Symphony [PCLM] 8.4   \n",
       "7564       Resolved-Completed   PROJ-9996                      Synergy 8.4   \n",
       "7567       Resolved-Completed   PROJ-9996                      Synergy 8.4   \n",
       "\n",
       "     backlog_id                               Backlog Name Feature ID  \\\n",
       "0       BL-3339                                      Cloud        NaN   \n",
       "1       BL-3339                                      Cloud    FR-9155   \n",
       "2       BL-3339                                      Cloud    FR-8238   \n",
       "39       BL-752  Pega Customer Service Development Backlog        NaN   \n",
       "48    GRP-13931                        Platform UI Backlog    FR-8192   \n",
       "...         ...                                        ...        ...   \n",
       "7561    BL-9394     FS - Client Lifecycle Management (8.4)        NaN   \n",
       "7562    BL-9394     FS - Client Lifecycle Management (8.4)        NaN   \n",
       "7563    BL-9394     FS - Client Lifecycle Management (8.4)        NaN   \n",
       "7564    BL-9394     FS - Client Lifecycle Management (8.4)        NaN   \n",
       "7567    BL-9394     FS - Client Lifecycle Management (8.4)        NaN   \n",
       "\n",
       "                         Feature Name  \\\n",
       "0                                 NaN   \n",
       "1           Scheduling Patch Installs   \n",
       "2     Global Operations Console (GOC)   \n",
       "39                                NaN   \n",
       "48                           Web APIs   \n",
       "...                               ...   \n",
       "7561                              NaN   \n",
       "7562                              NaN   \n",
       "7563                              NaN   \n",
       "7564                              NaN   \n",
       "7567                              NaN   \n",
       "\n",
       "                                               combined  \n",
       "0     issue  report  notification hi  team  report  ...  \n",
       "1     opd  prod  pre  schedule  validation  stick  p...  \n",
       "2     inflight  dbupgrde  task  validation  task  pr...  \n",
       "39    new  app  wizard  error laura  protano  run  e...  \n",
       "48    v  dx  api  automation  need  description  fix...  \n",
       "...                                                 ...  \n",
       "7561  qa  incorrect  sale  support  manager  onboard...  \n",
       "7562  fm  manage  product  fund  complete  default s...  \n",
       "7563  pdc  exception  null  pointer  excep  retail i...  \n",
       "7564  cib  case  stuck  client  synch  relate  add  ...  \n",
       "7567  pdc  exception  null  pointer  excepception  g...  \n",
       "\n",
       "[5434 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Setting up the Data for Training\n",
    "Now that our data is preprocessed and ready to go, we need to get the data into a suitable format for training a machine learning model. To do so we\n",
    "1. Get the one-hot-encoded representation of the backlog ids to which each bug belongs.\n",
    "2. Perform a train test split on our text and labels to separate out train data and test data. Here, we perform an 80/20 train-test split\n",
    "3. Use a TF/IDF Vectorizer to convert plain text descriptions into TF/IDF vectors. See the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) for details.\n",
    "    * Note that you can use a hashing vectorizer instead if you so choose. We found this method to be slightly less effective that TF/IDF, but it does have the advantage of being stateless. To use or test the hashing vectorizer in place of TF/IDF, comment out the TF/IDF code and uncomment the hashing vectorizer code.\n",
    "4. Convert all datatypes into `float32`s. `float32`s can be processed much faster than `float64`s on both GPU and CPU instances. Generally, we convert everything to `float32`s before training a model because the decreased precision almost never decreases model accuracy, but almost always decreases training speed. If you have an NVIDIA GPU available to you that also has a large number of \"tensor cores\" or \"half-precision cores,\" you might experiment with changing the data type instead to `float16` to improve training speed even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the one-hot-encoded representation of the backlog ids to which each bug belongs.\n",
    "backlog_labels = pd.get_dummies(assigned_bugs['backlog_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Perform a train test split on our text and labels to seperate out train data and test data.\n",
    "category='combined'\n",
    "random_state = 101 # random state is set to ensure our work is reproducable\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(assigned_bugs[category], backlog_labels, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4347, 16534)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Use a TF/IDF Vectorizer to convert plain text descprtions into TF/IDF vectors.\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True,\n",
    "                        binary=False,\n",
    "                        min_df=3,\n",
    "                        max_df=0.5, \n",
    "                        norm='l2', \n",
    "                        ngram_range=(1, 2),\n",
    "                        lowercase=True)\n",
    "\n",
    "train_features = pd.DataFrame(tfidf_vectorizer.fit_transform(train_features).toarray()) # Fit the Vectorizer to the train data\n",
    "test_features = pd.DataFrame(tfidf_vectorizer.transform(test_features).toarray()) # Only transform (don't fit) the test data to emulate real-world predictions\n",
    "\n",
    "#hashing_vectorizer = HashingVectorizer(n_features=2**14)\n",
    "#train_features = pd.DataFrame(hashing_vectorizer.transform(train_features).toarray())\n",
    "#test_features = pd.DataFrame(hashing_vectorizer.transform(test_features).toarray())\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features type:  <class 'pandas.core.frame.DataFrame'>\n",
      "train labels type:  <class 'pandas.core.frame.DataFrame'>\n",
      "train features shape:  (4347, 16534)\n",
      "train labels shape:  (4347, 47)\n",
      "train features value type:  float32\n",
      "train labels value type:  float32\n"
     ]
    }
   ],
   "source": [
    "# 4. Convert all datatypes to float32\n",
    "train_features = train_features.astype('float32')\n",
    "test_features = test_features.astype('float32')\n",
    "train_labels = train_labels.astype('float32')\n",
    "test_labels = test_labels.astype('float32')\n",
    "\n",
    "# Double Check That all data looks correct\n",
    "print(\"train features type: \" , type(train_features))\n",
    "print(\"train labels type: \", type(train_labels))\n",
    "print(\"train features shape: \", train_features.shape)\n",
    "print(\"train labels shape: \", train_labels.shape)\n",
    "print(\"train features value type: \", train_features.dtypes[0])\n",
    "print(\"train labels value type: \", train_labels.dtypes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Building The Model\n",
    "Now that our data is ready to go, we build the model we'll use to crunch the data. The function `build_tfidf_model` below defines our keras model. We won't go into too much depth here, but here are some general features that define the model we've built and a visual of the model's layers and output:\n",
    "\n",
    "**Parameters**:\n",
    "\n",
    "- Number of Layers: 2\n",
    "- Layer 1 size (# of neurons): 2048\n",
    "- Layer 2 size: 512\n",
    "- Activation Function: parameterized relu (\"prelu\")\n",
    "- Dropout Percentage: 30%\n",
    "- Optimizer: Adam\n",
    "- Learning Rate: 0.0001\n",
    "- Loss: kullback_leibler_divergence\n",
    "\n",
    "**Visual**:\n",
    "\n",
    "![TFIDF Deep Learning Model](../figures/model.png)\n",
    "\n",
    "\n",
    "**Hyperparameter Optimization**:\n",
    "\n",
    "In order to choose the above parameters, we performed hyperparameter optimization using a grid search. You can read more about hyperparameter optimization and grid search [here](https://en.wikipedia.org/wiki/Hyperparameter_optimization). Essentially, grid search attempts to find optimal model parameters simply by generating several hundreds or thousands of different model permutations, each with different parameters, and testing each model's accuracy/ loss. Grid search is considered the must rigorous method to perform hyperparameter optimization. After our grid search was finished, we simply copied the parameters from highest-performing model out of hundreds of models that we tested. The code for our hyperparameter-optimization grid search can be found in [hyperopt_tfidf.py](./hyperopt_tfidf.py)\n",
    "\n",
    "### Additional Notes:\n",
    "- The confidence bounding approach we use, termed ['Monte-Carlo Dropout'](https://arxiv.org/pdf/1506.02142.pdf), does not work when TensorFlow is in eager execution mode. As such, we always must disable eager execution before we build the model.\n",
    "- This confidence bounding approach uses dropout to test model confidence. In order to enable our model to use the approach, we insert a dropout layer in-between each of the Dense (Feature Detecting) layers, and set the parameter `trainable=True`. This trainable parameter must be enabled for the model to leverage Monte Carlo Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build our TF/IDF model:\n",
    "def build_tfidf_model(features, labels, optimizer, activations, drop_rate, lr, layer1_size, layer2_size=None, layer3_size=None, layer4_size=None):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=[len(features.keys())], name=\"TFIDF_Features\"))\n",
    "    model.add(Dense(layer1_size, input_shape=[len(features.keys())]))\n",
    "    \n",
    "    if activations[0] == \"leaky\":\n",
    "        model.add(LeakyReLU())\n",
    "    elif activations[0] == \"prelu\":\n",
    "        model.add(PReLU())\n",
    "    else:\n",
    "        model.add(Activation(activations[0]))     \n",
    "        \n",
    "    if layer2_size:\n",
    "        model.add(Dropout(drop_rate, trainable=True))\n",
    "        model.add(Dense(layer2_size))\n",
    "        \n",
    "        if activations[1] == \"leaky\":\n",
    "            model.add(LeakyReLU())\n",
    "        elif activations[0] == \"prelu\":\n",
    "            model.add(PReLU())\n",
    "        else:\n",
    "            model.add(Activation(activations[1]))      \n",
    "            \n",
    "            \n",
    "    if layer3_size:\n",
    "        model.add(Dropout(drop_rate, trainable=True))\n",
    "        model.add(Dense(layer3_size))\n",
    "        \n",
    "        if activations[2] == \"leaky\":\n",
    "            model.add(LeakyReLU())\n",
    "        elif activations[0] == \"prelu\":\n",
    "            model.add(PReLU())\n",
    "        else:\n",
    "            model.add(Activation(activations[2]))   \n",
    "            \n",
    "            \n",
    "    if layer4_size:\n",
    "        model.add(Dropout(drop_rate, trainable=True))\n",
    "        model.add(Dense(layer4_size))\n",
    "        \n",
    "        if activations[3] == \"leaky\":\n",
    "            model.add(LeakyReLU())\n",
    "        elif activations[0] == \"prelu\":\n",
    "            model.add(PReLU())\n",
    "        else:\n",
    "            model.add(Activation(activations[3]))\n",
    "            \n",
    "            \n",
    "    model.add(Dropout(drop_rate, trainable=True))\n",
    "    model.add(Dense(len(labels.keys()), activation='softmax', name=\"softmax_output\"))\n",
    "    \n",
    "    # Parameters\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(lr)\n",
    "    elif optimizer == 'adamax':\n",
    "        optimizer = tf.keras.optimizers.Adamax() # Use default learning rate for adamax\n",
    "    elif optimizer == 'nadam':\n",
    "        optimizer = tf.keras.optimizers.Nadam(lr)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(lr )\n",
    "    else:\n",
    "        print(\"ERROR: No valid optimizer passed\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    model.compile(loss='kullback_leibler_divergence',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable Eager Execution\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/envs/nlp-workspace/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Build the Model Itself\n",
    "\n",
    "# If the model already exists, make sure to deallocate it & clear system memory before allocating a new model:\n",
    "try:\n",
    "    assignment_model\n",
    "except NameError:\n",
    "    assignment_model = None\n",
    "    \n",
    "clear_memory() # Clear VRAM or RAM\n",
    "\n",
    "\n",
    "# Construct the model itself:\n",
    "assignment_model = build_tfidf_model(features = train_features, \n",
    "                                     labels = train_labels, \n",
    "                                     optimizer = 'adam',\n",
    "                                     activations = ['prelu', 'prelu'],\n",
    "                                     drop_rate=0.3,\n",
    "                                     lr=0.0001,\n",
    "                                     layer1_size = 2048,\n",
    "                                     layer2_size= 512, \n",
    "                                     layer3_size= None,\n",
    "                                     layer4_size= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2048)              33863680  \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 2048)              2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "softmax_output (Dense)       (None, 47)                24111     \n",
      "=================================================================\n",
      "Total params: 34,939,439\n",
      "Trainable params: 34,939,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Visualize the model's layers and output:\n",
    "assignment_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Training the Model\n",
    "We've now got our model and data ready to go. It's time for training. To train the model, we use a portion of the training data for for validation. Overall, we use about 70% of our data for training, about 10% for validation, and 20% for testing. This is a standard split for an ML Experiment. If you'd like more background on the difference between validation/ test sets, consult [this resource](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets).\n",
    "\n",
    "In the training function, we've added a couple of parameters we should define:\n",
    "- `early_stop`: [Early stopping](https://en.wikipedia.org/wiki/Early_stopping) is a method used to prevent a machine learning model from overfitting the training data. Essentially, early stopping forces a model to stop learning once its validation accuracy fails to improve for more than a set number of epochs. In our case, since we've set `patience` to 30, our model will stop training when it fails to improve its validation accuracy for 30 consecutive epochs. By setting the `restore_best_weights` option to `True`, we restore the 'version' of the model that produced the highest validation accuracy over the course of the training cycle. Restoring the best version of the model is important because model accuracy often starts to degrade towards the end of the training cycle as a model begins to overfit the training data\n",
    "\n",
    "- `workers`: workers defines the number of processes to spin up in order to train the machine learning model. The more processes, the faster the model will train (even when on a GPU instance), but you'll need at least 1 CPU core per process. We set the number of workers to the number of available CPUs on the machine training the model, but you can feel free to use less cores. Note that if you set `use_multiprocessing` to False, the training function will only spin up a single process.\n",
    "\n",
    "- `epochs`: epochs defines the number of times the model should 'loop through' the training dataset in its entirety while it is learning. In practice, we'll never train for even close to 1000 epochs. Due to early stopping, we found our models typically only trained for about 70-80 epochs max.\n",
    "\n",
    "- `batch_size`: The batch size is the number of training examples the model will 'take in' at once. Our model could handle taking in 128 TF/IDF Vectors and corresponding backlog label vectors at once. If your machine has less RAM or VRAM, however, you may need to decrease the batch size to avoid overloading the system memory. Attempt to choose a batch size that is a power of 4.\n",
    "\n",
    "For a more in-depth and less dumbed-down description of epochs and batch size, check out [this resource](https://docs.paperspace.com/machine-learning/wiki/epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3912 samples, validate on 435 samples\n",
      "Epoch 1/1000\n",
      "3912/3912 [==============================] - 1s 365us/sample - loss: 3.8169 - accuracy: 0.1582 - val_loss: 3.7620 - val_accuracy: 0.2023\n",
      "Epoch 2/1000\n",
      "3912/3912 [==============================] - 1s 288us/sample - loss: 3.6913 - accuracy: 0.1723 - val_loss: 3.5766 - val_accuracy: 0.2000\n",
      "Epoch 3/1000\n",
      "3912/3912 [==============================] - 1s 273us/sample - loss: 3.4654 - accuracy: 0.1702 - val_loss: 3.3237 - val_accuracy: 0.2000\n",
      "Epoch 4/1000\n",
      "3912/3912 [==============================] - 1s 280us/sample - loss: 3.2305 - accuracy: 0.1725 - val_loss: 3.1253 - val_accuracy: 0.2092\n",
      "Epoch 5/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 3.0079 - accuracy: 0.2168 - val_loss: 2.9401 - val_accuracy: 0.2529\n",
      "Epoch 6/1000\n",
      "3912/3912 [==============================] - 1s 275us/sample - loss: 2.7908 - accuracy: 0.2630 - val_loss: 2.7664 - val_accuracy: 0.3034\n",
      "Epoch 7/1000\n",
      "3912/3912 [==============================] - 1s 319us/sample - loss: 2.5723 - accuracy: 0.3443 - val_loss: 2.5901 - val_accuracy: 0.3678\n",
      "Epoch 8/1000\n",
      "3912/3912 [==============================] - 1s 283us/sample - loss: 2.3548 - accuracy: 0.4292 - val_loss: 2.4193 - val_accuracy: 0.4345\n",
      "Epoch 9/1000\n",
      "3912/3912 [==============================] - 1s 274us/sample - loss: 2.1419 - accuracy: 0.5153 - val_loss: 2.2606 - val_accuracy: 0.4851\n",
      "Epoch 10/1000\n",
      "3912/3912 [==============================] - 1s 255us/sample - loss: 1.9377 - accuracy: 0.5859 - val_loss: 2.1077 - val_accuracy: 0.5356\n",
      "Epoch 11/1000\n",
      "3912/3912 [==============================] - 1s 264us/sample - loss: 1.7517 - accuracy: 0.6355 - val_loss: 1.9774 - val_accuracy: 0.5586\n",
      "Epoch 12/1000\n",
      "3912/3912 [==============================] - 1s 280us/sample - loss: 1.5742 - accuracy: 0.6833 - val_loss: 1.8560 - val_accuracy: 0.5885\n",
      "Epoch 13/1000\n",
      "3912/3912 [==============================] - 1s 280us/sample - loss: 1.4144 - accuracy: 0.7367 - val_loss: 1.7466 - val_accuracy: 0.6046\n",
      "Epoch 14/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 1.2660 - accuracy: 0.7715 - val_loss: 1.6516 - val_accuracy: 0.6322\n",
      "Epoch 15/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 1.1385 - accuracy: 0.8078 - val_loss: 1.5617 - val_accuracy: 0.6713\n",
      "Epoch 16/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 1.0155 - accuracy: 0.8397 - val_loss: 1.4832 - val_accuracy: 0.6920\n",
      "Epoch 17/1000\n",
      "3912/3912 [==============================] - 1s 278us/sample - loss: 0.9131 - accuracy: 0.8589 - val_loss: 1.4116 - val_accuracy: 0.7057\n",
      "Epoch 18/1000\n",
      "3912/3912 [==============================] - 1s 278us/sample - loss: 0.8146 - accuracy: 0.8908 - val_loss: 1.3548 - val_accuracy: 0.7218\n",
      "Epoch 19/1000\n",
      "3912/3912 [==============================] - 1s 266us/sample - loss: 0.7309 - accuracy: 0.9001 - val_loss: 1.3007 - val_accuracy: 0.7356\n",
      "Epoch 20/1000\n",
      "3912/3912 [==============================] - 1s 266us/sample - loss: 0.6598 - accuracy: 0.9187 - val_loss: 1.2528 - val_accuracy: 0.7494\n",
      "Epoch 21/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 0.5862 - accuracy: 0.9294 - val_loss: 1.2085 - val_accuracy: 0.7586\n",
      "Epoch 22/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 0.5269 - accuracy: 0.9397 - val_loss: 1.1780 - val_accuracy: 0.7655\n",
      "Epoch 23/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 0.4698 - accuracy: 0.9466 - val_loss: 1.1447 - val_accuracy: 0.7724\n",
      "Epoch 24/1000\n",
      "3912/3912 [==============================] - 1s 277us/sample - loss: 0.4263 - accuracy: 0.9540 - val_loss: 1.1185 - val_accuracy: 0.7701\n",
      "Epoch 25/1000\n",
      "3912/3912 [==============================] - 1s 280us/sample - loss: 0.3792 - accuracy: 0.9604 - val_loss: 1.0959 - val_accuracy: 0.7770\n",
      "Epoch 26/1000\n",
      "3912/3912 [==============================] - 1s 277us/sample - loss: 0.3432 - accuracy: 0.9691 - val_loss: 1.0745 - val_accuracy: 0.7770\n",
      "Epoch 27/1000\n",
      "3912/3912 [==============================] - 1s 285us/sample - loss: 0.3109 - accuracy: 0.9734 - val_loss: 1.0566 - val_accuracy: 0.7862\n",
      "Epoch 28/1000\n",
      "3912/3912 [==============================] - 1s 274us/sample - loss: 0.2808 - accuracy: 0.9744 - val_loss: 1.0420 - val_accuracy: 0.7816\n",
      "Epoch 29/1000\n",
      "3912/3912 [==============================] - 1s 264us/sample - loss: 0.2566 - accuracy: 0.9783 - val_loss: 1.0271 - val_accuracy: 0.7793\n",
      "Epoch 30/1000\n",
      "3912/3912 [==============================] - 1s 272us/sample - loss: 0.2335 - accuracy: 0.9770 - val_loss: 1.0164 - val_accuracy: 0.7862\n",
      "Epoch 31/1000\n",
      "3912/3912 [==============================] - 1s 273us/sample - loss: 0.2089 - accuracy: 0.9819 - val_loss: 1.0045 - val_accuracy: 0.7862\n",
      "Epoch 32/1000\n",
      "3912/3912 [==============================] - 1s 274us/sample - loss: 0.1897 - accuracy: 0.9803 - val_loss: 0.9932 - val_accuracy: 0.7862\n",
      "Epoch 33/1000\n",
      "3912/3912 [==============================] - 1s 273us/sample - loss: 0.1751 - accuracy: 0.9816 - val_loss: 0.9899 - val_accuracy: 0.7862\n",
      "Epoch 34/1000\n",
      "3912/3912 [==============================] - 1s 273us/sample - loss: 0.1630 - accuracy: 0.9834 - val_loss: 0.9816 - val_accuracy: 0.7862\n",
      "Epoch 35/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 0.1512 - accuracy: 0.9829 - val_loss: 0.9744 - val_accuracy: 0.7908\n",
      "Epoch 36/1000\n",
      "3912/3912 [==============================] - 1s 276us/sample - loss: 0.1372 - accuracy: 0.9839 - val_loss: 0.9725 - val_accuracy: 0.7862\n",
      "Epoch 37/1000\n",
      "3912/3912 [==============================] - 1s 277us/sample - loss: 0.1250 - accuracy: 0.9870 - val_loss: 0.9664 - val_accuracy: 0.7885\n",
      "Epoch 38/1000\n",
      "3912/3912 [==============================] - 1s 270us/sample - loss: 0.1187 - accuracy: 0.9854 - val_loss: 0.9623 - val_accuracy: 0.7839\n",
      "Epoch 39/1000\n",
      "3912/3912 [==============================] - 1s 267us/sample - loss: 0.1099 - accuracy: 0.9882 - val_loss: 0.9619 - val_accuracy: 0.7862\n",
      "Epoch 40/1000\n",
      "3912/3912 [==============================] - 1s 273us/sample - loss: 0.1011 - accuracy: 0.9882 - val_loss: 0.9577 - val_accuracy: 0.7816\n",
      "Epoch 41/1000\n",
      "3912/3912 [==============================] - 1s 277us/sample - loss: 0.0961 - accuracy: 0.9890 - val_loss: 0.9536 - val_accuracy: 0.7839\n",
      "Epoch 42/1000\n",
      "3912/3912 [==============================] - 1s 278us/sample - loss: 0.0917 - accuracy: 0.9872 - val_loss: 0.9560 - val_accuracy: 0.7908\n",
      "Epoch 43/1000\n",
      "3912/3912 [==============================] - 1s 274us/sample - loss: 0.0834 - accuracy: 0.9885 - val_loss: 0.9524 - val_accuracy: 0.7816\n",
      "Epoch 44/1000\n",
      "3912/3912 [==============================] - 1s 278us/sample - loss: 0.0818 - accuracy: 0.9885 - val_loss: 0.9513 - val_accuracy: 0.7839\n",
      "Epoch 45/1000\n",
      "3912/3912 [==============================] - 1s 279us/sample - loss: 0.0786 - accuracy: 0.9862 - val_loss: 0.9492 - val_accuracy: 0.7885\n",
      "Epoch 46/1000\n",
      "3912/3912 [==============================] - 1s 280us/sample - loss: 0.0724 - accuracy: 0.9872 - val_loss: 0.9508 - val_accuracy: 0.7954\n",
      "Epoch 47/1000\n",
      "3912/3912 [==============================] - 1s 276us/sample - loss: 0.0702 - accuracy: 0.9880 - val_loss: 0.9475 - val_accuracy: 0.7977\n",
      "Epoch 48/1000\n",
      "3912/3912 [==============================] - 1s 270us/sample - loss: 0.0668 - accuracy: 0.9885 - val_loss: 0.9466 - val_accuracy: 0.7931\n",
      "Epoch 49/1000\n",
      "3912/3912 [==============================] - 1s 276us/sample - loss: 0.0635 - accuracy: 0.9890 - val_loss: 0.9484 - val_accuracy: 0.7908\n",
      "Epoch 50/1000\n",
      "3912/3912 [==============================] - 1s 280us/sample - loss: 0.0617 - accuracy: 0.9885 - val_loss: 0.9498 - val_accuracy: 0.7885\n",
      "Epoch 51/1000\n",
      "3912/3912 [==============================] - 1s 276us/sample - loss: 0.0601 - accuracy: 0.9888 - val_loss: 0.9473 - val_accuracy: 0.7931\n",
      "Epoch 52/1000\n",
      "3912/3912 [==============================] - 1s 275us/sample - loss: 0.0578 - accuracy: 0.9895 - val_loss: 0.9484 - val_accuracy: 0.7908\n",
      "Epoch 53/1000\n",
      "3912/3912 [==============================] - 1s 276us/sample - loss: 0.0601 - accuracy: 0.9870 - val_loss: 0.9503 - val_accuracy: 0.7885\n",
      "Epoch 54/1000\n",
      "3912/3912 [==============================] - 1s 278us/sample - loss: 0.0510 - accuracy: 0.9898 - val_loss: 0.9497 - val_accuracy: 0.7931\n",
      "Epoch 55/1000\n",
      "3912/3912 [==============================] - 1s 280us/sample - loss: 0.0512 - accuracy: 0.9900 - val_loss: 0.9494 - val_accuracy: 0.7908\n",
      "Epoch 56/1000\n",
      "3912/3912 [==============================] - 1s 277us/sample - loss: 0.0508 - accuracy: 0.9882 - val_loss: 0.9516 - val_accuracy: 0.7885\n",
      "Epoch 57/1000\n",
      "3912/3912 [==============================] - 1s 277us/sample - loss: 0.0482 - accuracy: 0.9898 - val_loss: 0.9529 - val_accuracy: 0.7908\n",
      "Epoch 58/1000\n",
      "3912/3912 [==============================] - 1s 265us/sample - loss: 0.0475 - accuracy: 0.9908 - val_loss: 0.9526 - val_accuracy: 0.7908\n",
      "Epoch 59/1000\n",
      "1024/3912 [======>.......................] - ETA: 0s - loss: 0.0411 - accuracy: 0.9941"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cda9dfb84dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   workers=workers, use_multiprocessing=use_multiprocessing)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nlp-workspace/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/nlp-workspace/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/nlp-workspace/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mins\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m               \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m               \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m               \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp-workspace/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    527\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     return [\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp-workspace/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    527\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     return [\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define Params for this model:\n",
    "import multiprocessing\n",
    "workers = multiprocessing.cpu_count()\n",
    "use_multiprocessing = workers > 1\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', restore_best_weights=True, patience=20)\n",
    "\n",
    "\n",
    "history_tfidf = assignment_model.fit(\n",
    "  train_features, train_labels,\n",
    "  batch_size=128,\n",
    "  epochs=1000, validation_split=0.1, verbose=1,\n",
    "  callbacks=[early_stop],\n",
    "  workers=workers, use_multiprocessing=use_multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Training History\n",
    "plot_history(history_tfidf, \"Val Accuracy: TFIDF + Deep Learning Model\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Saving the Model\n",
    "In order to use the model we've just trained in production, we'll need to save the model and all of its dependencies. This way, we'll be able to easily reload the model in production to perform predictions. Below we save...\n",
    "\n",
    "- `tfidf_vectorizer`: The TF/IDF Vectorizer was 'fit' to the training dataset, and its vocabulary encompasses all of the words that show up in our training emails. In order to prepare plain-text/ HTML files to be fed into our model during deployment, we'll need to use this vectorizer once again to transform that text/HTML into the vectors that our deep learning model expects as input.\n",
    "- `label_to_id`: This variable stores a simple dictionary that maps prediction indices (indices of the labels in the one-hot-encoded label representation) to actual backlog-id names. Without this dictionary, we wouldn't be able to understanding the meaning of our model predictions.\n",
    "- `assignment_model`: lastly, of course, we save the classifier itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BL-3346'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a dictionary that maps prediction indicies \n",
    "# (indicies of one-hot-encoded labels) to actual backlog ID names \n",
    "label_to_id = {}\n",
    "for i, col in enumerate(test_labels.columns):\n",
    "    label_to_id[i] = col\n",
    "\n",
    "# Test:\n",
    "label_to_id[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Directory to save into:\n",
    "! mkdir -p ../saved_models/tfidf_model/\n",
    "# Save tfidf_vectorizer\n",
    "pickle.dump(tfidf_vectorizer, open(\"../saved_models/tfidf_model/tfidf_vectorizer.pkl\", \"wb\"))\n",
    "# Save assignment_model\n",
    "assignment_model.save('../saved_models/tfidf_model/tfidf_classifier.h5')\n",
    "# Save label_to_id dictionary\n",
    "pickle.dump(label_to_id, open('../saved_models/tfidf_model/label_to_id.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Testing Model + Generating Predictions:\n",
    "To generate model predictions, we apply the Monte Carlo Dropout confidence bounding approach described in ['Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning\n",
    "'](https://arxiv.org/pdf/1506.02142.pdf). We've developed two prediction functions that use Monte Carlo Dropout under the hood\n",
    "- `test_with_uncertainty` - designed to be used to test model accuracy on a test set, and\n",
    "- `predict_with_uncertainty`, designed to be used in production to generate a prediction for a single email.\n",
    "You can find the code for these functions in [MLFunctions.py](../nlp_engine/MLFunctions.py). We've listed the function headers below to describe how each of these functions work.\n",
    "\n",
    "When we test our model, we'll use the function `test_with_uncertainty` to obtain our model's predictions for each sample in the test set, along with the associated confidence value for  each of those predictions. This way, we can evaluate the accuracy of the model at different confidence intervals.\n",
    "```python\n",
    "def test_with_uncertainty(model, test_features: pd.DataFrame, test_labels: pd.DataFrame, label_to_id: dict, n_iter=10) -> pd.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    USE FOR TESTING\n",
    "    ---------------\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        - model: a keras model trained with Monte Carlo Dropout\n",
    "\n",
    "        - test_features: one or multiple samples (1 sample = 1 vector of \n",
    "                         test_features).\n",
    "\n",
    "        - test_labels: the ground-truth labels corresponding to the samples. \n",
    "                       (one-hot-encoded)\n",
    "\n",
    "        - label_to_id: A dictionary that maps prediction indicies (indicies of\n",
    "                       the softmax outputs of the model) to label names. \n",
    "\n",
    "        - n_iter: the number of stochastic forward passes you'd like your model \n",
    "                  to perform for each given test sample. i.e. for n_iter=10, the\n",
    "                  function applies 10 distinct dropout schemas and generates\n",
    "                  10 different softmax outputs from the model. It then takes the final or 'master'\n",
    "                  prediction to be the maximum softmax index with the highest overall probability\n",
    "                  (i.e. final prediction = average prediction over all 10 trials) and the uncertainty \n",
    "                  to be the Standard Deviation of the set of 10 softmax outputs (more variable softmax output \n",
    "                  = more uncertainty)\n",
    "    \n",
    "    Returns: preds_df, a dataframe of labels predicted by your model, ground truth lables, and prediction\n",
    "             uncertainty values.\n",
    "    \"\"\"\n",
    "    \n",
    "def predict_with_uncertainty(model, test_features: pd.DataFrame, label_to_id: dict, n_iter=10) -> tuple\n",
    "    \n",
    "    \"\"\"\n",
    "    USE FOR DEPLOYMENT\n",
    "    ------------------\n",
    "\n",
    "    Wheras the above function is used during the testing phase (testing monte \n",
    "    carlo accuracies), this function should be used for deployment. Note that\n",
    "    there are no ground-truth labels passed into the function.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        - model: Save as above\n",
    "\n",
    "        - test_features: a SINGLE sample (1 sample = 1 vector of \n",
    "                         test_features).\n",
    "\n",
    "        - label_to_id: Save as above\n",
    "\n",
    "        - n_iter: Same as above\n",
    "   \n",
    "    Returns: a tuple, including the predicted label value and an uncertainty value\n",
    "             ... i.e. return  (prediction id, uncertainty)\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "preds_df = test_with_uncertainty(assignment_model, test_features, test_labels, label_to_id, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Label</th>\n",
       "      <th>Uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BL-3289</td>\n",
       "      <td>BL-3289</td>\n",
       "      <td>0.043093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BL-3289</td>\n",
       "      <td>BL-3289</td>\n",
       "      <td>0.003870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRP-3974</td>\n",
       "      <td>GRP-3974</td>\n",
       "      <td>0.056304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRP-28665</td>\n",
       "      <td>GRP-28665</td>\n",
       "      <td>0.068767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BL-3339</td>\n",
       "      <td>GRP-20686</td>\n",
       "      <td>0.095061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>GRP-13931</td>\n",
       "      <td>GRP-13931</td>\n",
       "      <td>0.009416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>GRP-13931</td>\n",
       "      <td>BL-2287</td>\n",
       "      <td>0.119338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>BL-2285</td>\n",
       "      <td>BL-2285</td>\n",
       "      <td>0.006764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>BL-752</td>\n",
       "      <td>BL-752</td>\n",
       "      <td>0.002787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>BL-6113</td>\n",
       "      <td>BL-6113</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction      Label  Uncertainty\n",
       "0       BL-3289    BL-3289     0.043093\n",
       "1       BL-3289    BL-3289     0.003870\n",
       "2      GRP-3974   GRP-3974     0.056304\n",
       "3     GRP-28665  GRP-28665     0.068767\n",
       "4       BL-3339  GRP-20686     0.095061\n",
       "...         ...        ...          ...\n",
       "1082  GRP-13931  GRP-13931     0.009416\n",
       "1083  GRP-13931    BL-2287     0.119338\n",
       "1084    BL-2285    BL-2285     0.006764\n",
       "1085     BL-752     BL-752     0.002787\n",
       "1086    BL-6113    BL-6113     0.026400\n",
       "\n",
       "[1087 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize and evaluate the prediction/ uncertainty values\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Accuracy\n",
    "---\n",
    "\n",
    "Now that we've gotten our model predictions, we can pass the resulting `preds_df` DataFrame into another function `get_monte_carlo accuracy`. `get_monte_carlo accuracy` takes as input a predictions DataFrame, as well as a threshold uncertainty score. The function will then return the model's accuracy on all test samples that were predicted with an uncertainty value *below* the threshold uncertainty score. Further, it will let us know how much of the test set was discarded when the confidence threshold was applied.\n",
    "\n",
    "Ideally, you want to find a balance between accuracy and efficiency. It may be the case that that your model can achieve 80% accuracy on the entire test set (i.e. NO uncertainty threshold), however, your model can achieve a much higher 95% accuracy on 60% of the test set if you allow the model to throw emails that it is unable to confidently place into a queue for human review. In this case, you must decide whether you prefer\n",
    "- An 80% accurate model that automates 100% of the work or...\n",
    "- a 95% accurate model that automates 60% of the work.\n",
    "\n",
    "To determine the right balance for you, feel free to play around with the threshold uncertainty value and determine which threshold is best for your use case.\n",
    "\n",
    "**NOTE**: Do not change the `n_iter` value unless you truly understand what this parameter means. If you do decide to change the `n_iter` value, make sure that the model uses the exact same `n_iter` value in production (i.e. make sure that both test_with_uncertainty and predict_with_uncertainty take the same `n_iter` value. Changing the `n_iter` value alters the scale of the `uncertainty` metric, so we need to make sure `n_iter` is consistant across testing and production to ensure that the threshold uncertainty value we determine during testing works as we expect it to work in production.\n",
    "\n",
    "--- \n",
    "### Steps:\n",
    "- Test the models accuracy across the **entire** test set by setting the uncertainty threshold to `None`, and compare its accuracy to a dummy classifier (i.e. a model that classifies every email into the most frequently occuring backlog. \n",
    "- Show an example for how we can test the models accuracy at a particular uncertainty threshold. \n",
    "- Show a graph of the relationship between the percentage of testing data retained and the model accuracy\n",
    "- Show how we can select an uncertainty thrshold based on a target accuracy, or a target ammount of data we want to retain in production (the percentage of the bug classification that will be automated by the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set reduced to % 100\n",
      "Accuracy : % 77.92088316467341\n"
     ]
    }
   ],
   "source": [
    "retained, accuracy = get_monte_carlo_accuracy(preds_df=preds_df, threshold=None)\n",
    "print('Test set reduced to %', retained)\n",
    "print('Accuracy : %', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Rule Baseline Accuracy: % 18.215271389144434\n",
      "Random (Uniform) Baseline Accuracy: % 2.2999080036798527\n"
     ]
    }
   ],
   "source": [
    "# For reference, here is the zero-rule and random baseline accuracies\n",
    "# on the test set:\n",
    "\n",
    "# DummyClassifier only accepts numeric categorical labels, so we convert\n",
    "# our one-hot-encoded labels back to standard levels before passing in:\n",
    "int_train_labels = train_labels.idxmax(axis=1)\n",
    "int_test_labels = test_labels.idxmax(axis=1)\n",
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "clf.fit(train_features, int_train_labels)\n",
    "print(\"Zero-Rule Baseline Accuracy: %\", clf.score(test_features, int_test_labels) * 100)\n",
    "\n",
    "clf = DummyClassifier(strategy='uniform')\n",
    "clf.fit(train_features, int_train_labels)\n",
    "print(\"Random (Uniform) Baseline Accuracy: %\", clf.score(test_features, int_test_labels) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set reduced to % 41.582336706531734\n",
      "Accuracy : % 94.24778761061947\n"
     ]
    }
   ],
   "source": [
    "# Accuracy with an uncertainty threshold applied:\n",
    "retained, accuracy = get_monte_carlo_accuracy(preds_df=preds_df, threshold=0.04)\n",
    "print('Test set reduced to %', retained)\n",
    "print('Accuracy : %', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BL-3289', 0.04268224690757483)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this function to generate a prediction on a single email. \n",
    "# This function is not relevant in testing the model, but will be used to classify incoming emails later on in production\n",
    "predict_with_uncertainty(assignment_model, test_features.iloc[0], label_to_id, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.34438305709024"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph the trade-off between effeciency and accuracy:\n",
    "graph_confidence(preds_df, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLFunctions import acc_to_uncertainty, proportion_to_uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Threshold \n",
    "to use in production based on target ammount of data retained or based on target accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of test data retained 69.91720331186752\n",
      "Exact accuracy 85.0\n",
      "Threshold: 0.10143798283467881\n"
     ]
    }
   ],
   "source": [
    "# Retain 70% of data\n",
    "threshold = proportion_to_uncertainty(preds_df, target_prop=70)\n",
    "print('Threshold:', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of test data retained 53.26586936522539\n",
      "Exact accuracy 90.15544041450777\n",
      "Threshold: 0.06581715428722074\n"
     ]
    }
   ],
   "source": [
    "# Reach 90% of accuracy\n",
    "threshold = acc_to_uncertainty(preds_df, target_acc=90)\n",
    "print('Threshold:', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deallocate the model:\n",
    "clear_memory(assignment_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-workspace",
   "language": "python",
   "name": "nlp-workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
